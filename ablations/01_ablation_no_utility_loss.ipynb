{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "82822fbb",
        "2c7a31bc",
        "50188a72",
        "e8ad280c",
        "cf2a74a7",
        "a0344b47",
        "0e0b33ee",
        "b18c851c",
        "36c37a79"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13734423,
          "sourceType": "datasetVersion",
          "datasetId": 8738676
        },
        {
          "sourceId": 13739688,
          "sourceType": "datasetVersion",
          "datasetId": 8742255
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "a520df35",
      "cell_type": "markdown",
      "source": [
        "## 1. Setup & GPU Detection üîß"
      ],
      "metadata": {
        "id": "a520df35"
      }
    },
    {
      "id": "GDMQb-e0EP4i",
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -q transformers datasets\n",
        "print(\"‚úÖ transformers and datasets installed.\")"
      ],
      "metadata": {
        "id": "GDMQb-e0EP4i",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5797b4fc",
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "from typing import List, Tuple, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# FORCE GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"GPU ENABLED: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   VRAM Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
        "    # Clear cache\n",
        "    torch.cuda.empty_cache()\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"WARNING: Running on CPU - Training will be VERY slow!\")\n",
        "    print(\"   Consider restarting kernel and selecting a CUDA-enabled Python environment\")\n",
        "\n",
        "print(f\"\\nDevice set to: {device}\")\n",
        "print(f\"   PyTorch version: {torch.__version__}\")\n",
        "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "# Hyperparameters (GPU-optimized)\n",
        "BATCH_SIZE = 16 if torch.cuda.is_available() else 8\n",
        "NUM_EPOCHS = 5 if torch.cuda.is_available() else 2\n",
        "LEARNING_RATE = 3e-4\n",
        "TEMPERATURE = 0.05\n",
        "ADAPTER_SIZE = 256\n",
        "TRAIN_SAMPLE = 5  # Augmentation factor\n",
        "\n",
        "print(f\"\\nHyperparameters:\")\n",
        "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"   Temperature: {TEMPERATURE}\")\n",
        "\n",
        "# Load tokenizer for global use\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "print(f\"\\nTokenizer loaded: bert-base-uncased\")\n"
      ],
      "metadata": {
        "id": "5797b4fc",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cdbddbc5",
      "cell_type": "markdown",
      "source": [
        "## 2. Helper Functions & Classes üõ†Ô∏è\n",
        "\n",
        "This section contains all the core functionality:\n",
        "- **Contrastive Loss Functions** (InfoNCE, Triplet, Margin)\n",
        "- **Adapter Modules** (Lightweight debiasing layers)\n",
        "- **Evaluation Metrics** (CrowS-Pairs, PLL scoring)\n",
        "- **Built-in Bias Examples** (31 carefully curated pairs)"
      ],
      "metadata": {
        "id": "cdbddbc5"
      }
    },
    {
      "id": "cfc0270e",
      "cell_type": "code",
      "source": [
        "# # ============================================================================\n",
        "# # CONTRASTIVE LOSS FUNCTIONS\n",
        "# # ============================================================================\n",
        "\n",
        "# class InfoNCELoss(nn.Module):\n",
        "#     \"\"\"InfoNCE contrastive loss for pushing biased representations apart\"\"\"\n",
        "#     def __init__(self, temperature=0.07):\n",
        "#         super().__init__()\n",
        "#         self.temperature = temperature\n",
        "\n",
        "#     def forward(self, anchor, positive):\n",
        "#         \"\"\"\n",
        "#         Args:\n",
        "#             anchor: [batch_size, hidden_dim] - stereotypical embeddings\n",
        "#             positive: [batch_size, hidden_dim] - anti-stereotypical embeddings\n",
        "#         \"\"\"\n",
        "#         # Normalize\n",
        "#         anchor = F.normalize(anchor, dim=1)\n",
        "#         positive = F.normalize(positive, dim=1)\n",
        "\n",
        "#         # Compute similarity matrix\n",
        "#         logits = torch.matmul(anchor, positive.T) / self.temperature\n",
        "\n",
        "#         # Labels: we want to maximize distance, so inverse of similarity\n",
        "#         batch_size = anchor.size(0)\n",
        "#         labels = torch.arange(batch_size).to(anchor.device)\n",
        "\n",
        "#         # Cross-entropy loss (higher similarity to different = better debiasing)\n",
        "#         loss = F.cross_entropy(logits, labels)\n",
        "#         return loss\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ADAPTER MODULES\n",
        "# ============================================================================\n",
        "\n",
        "class DebiasAdapter(nn.Module):\n",
        "    \"\"\"Lightweight adapter for bias mitigation\"\"\"\n",
        "    def __init__(self, hidden_size=768, adapter_size=256):\n",
        "        super().__init__()\n",
        "        self.adapter = nn.Sequential(\n",
        "            nn.Linear(hidden_size, adapter_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(adapter_size, hidden_size),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "\n",
        "        # Initialize with small weights for stability\n",
        "        for module in self.adapter:\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.normal_(module.weight, std=0.01)\n",
        "                nn.init.zeros_(module.bias)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # Residual connection\n",
        "        return hidden_states + self.adapter(hidden_states)\n",
        "\n",
        "\n",
        "class AdaptedBERT(nn.Module):\n",
        "    \"\"\"BERT with debiasing adapter\"\"\"\n",
        "    def __init__(self, base_model, adapter_size=256):\n",
        "        super().__init__()\n",
        "        self.bert = base_model.bert\n",
        "        self.adapter = DebiasAdapter(base_model.config.hidden_size, adapter_size)\n",
        "        self.config = base_model.config\n",
        "\n",
        "        # Freeze BERT, only train adapter\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for param in self.adapter.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        last_hidden = outputs.last_hidden_state\n",
        "        adapted = self.adapter(last_hidden)\n",
        "        return adapted[:, 0, :]  # Return [CLS] token\n",
        "\n",
        "    def get_full_model(self):\n",
        "        \"\"\"Return the full model for evaluation\"\"\"\n",
        "        return self.bert.base_model if hasattr(self.bert, 'base_model') else self.bert\n",
        "\n",
        "\n",
        "print(\"‚úÖ Loss functions and adapter classes defined\")"
      ],
      "metadata": {
        "id": "cfc0270e",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5563d2cd",
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from tqdm.auto import tqdm # Make sure tqdm is imported here\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ============================================================================\n",
        "# EVALUATION FUNCTIONS (UPDATED)\n",
        "# ============================================================================\n",
        "\n",
        "def compute_pll_score(model, tokenizer, text, device, max_length=128):\n",
        "    \"\"\"Compute Pseudo-Log-Likelihood score for bias evaluation\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
        "                      max_length=max_length, padding=False)\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs.get(\"attention_mask\", torch.ones_like(input_ids)).to(device)\n",
        "\n",
        "    seq_len = input_ids.shape[1]\n",
        "    total_log_prob = 0.0\n",
        "\n",
        "    # Handle cases where text is too short or empty\n",
        "    if seq_len <= 2:\n",
        "        return 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Mask each token and predict it\n",
        "        for i in range(1, seq_len - 1):  # Skip [CLS] and [SEP]\n",
        "            masked_input = input_ids.clone()\n",
        "            original_token = masked_input[0, i].item()\n",
        "            masked_input[0, i] = tokenizer.mask_token_id\n",
        "\n",
        "            outputs = model(input_ids=masked_input, attention_mask=attention_mask)\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "\n",
        "            log_probs = F.log_softmax(logits[0, i, :], dim=0)\n",
        "            total_log_prob += log_probs[original_token].item()\n",
        "\n",
        "    # Return average log-likelihood\n",
        "    return total_log_prob / (seq_len - 2)\n",
        "\n",
        "\n",
        "def evaluate_on_crows_pairs(model, tokenizer, pairs, device):\n",
        "    \"\"\"Evaluate model on CrowS-Pairs (Handles both key formats)\"\"\"\n",
        "    stereo_wins = 0\n",
        "    by_type = defaultdict(lambda: {'stereo_wins': 0, 'total': 0})\n",
        "\n",
        "    for pair in tqdm(pairs, desc=\"Evaluating\"):\n",
        "\n",
        "        # --- THIS IS THE FIX ---\n",
        "        # Get stereo sentence (check for 'stereo' key, fallback to 'stereotype')\n",
        "        stereo_sent = pair.get('stereo', pair.get('stereotype'))\n",
        "\n",
        "        # Get anti-stereo sentence (check for 'anti' key, fallback to 'anti_stereotype')\n",
        "        anti_sent = pair.get('anti', pair.get('anti_stereotype'))\n",
        "        # ---------------------\n",
        "\n",
        "        if not stereo_sent or not anti_sent:\n",
        "            continue # Skip if sentences are missing\n",
        "\n",
        "        pll_stereo = compute_pll_score(model, tokenizer, stereo_sent, device)\n",
        "        pll_anti = compute_pll_score(model, tokenizer, anti_sent, device)\n",
        "\n",
        "        bias_type = pair.get('bias_type', 'unknown')\n",
        "        by_type[bias_type]['total'] += 1\n",
        "\n",
        "        if pll_stereo > pll_anti:\n",
        "            stereo_wins += 1\n",
        "            by_type[bias_type]['stereo_wins'] += 1\n",
        "\n",
        "    preference = stereo_wins / len(pairs) if pairs else 0.5\n",
        "\n",
        "    type_preferences = {}\n",
        "    for bias_type, scores in by_type.items():\n",
        "        if scores['total'] > 0:\n",
        "            type_preferences[bias_type] = {\n",
        "                'preference': scores['stereo_wins'] / scores['total'],\n",
        "                'total': scores['total']\n",
        "            }\n",
        "\n",
        "    return {\n",
        "        'preference': preference,\n",
        "        'stereo_wins': stereo_wins,\n",
        "        'total': len(pairs),\n",
        "        'by_type': type_preferences\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Evaluation functions defined (now robust to both data formats)\")"
      ],
      "metadata": {
        "id": "5563d2cd",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "052802d1",
      "cell_type": "markdown",
      "source": [
        "## 12. Enhanced Strategy: Contrastive PLL Loss (Target: 50%) üéØ\n",
        "\n",
        "The old successful notebook used a different loss function that directly optimizes for **neutrality (50% bias)**.\n",
        "\n",
        "**Key improvements:**\n",
        "1. **Squared difference loss**: `(pll_stereo - pll_anti)¬≤` ‚Üí pushes both PLLs to be equal\n",
        "2. **Larger CrowS-Pairs dataset**: Load full HuggingFace dataset (1508 pairs vs our 31)\n",
        "3. **Per-pair gradient**: Train on individual pairs instead of batched embeddings\n",
        "\n",
        "This should bring bias from 77% ‚Üí 50% (neutral) with sufficient epochs."
      ],
      "metadata": {
        "id": "052802d1"
      }
    },
    {
      "id": "ca720b83",
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üì• DOWNLOADING FULL CROWS-PAIRS DATASET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import io\n",
        "\n",
        "try:\n",
        "    # Download CrowS-Pairs directly from GitHub\n",
        "    url = \"https://raw.githubusercontent.com/nyu-mll/crows-pairs/master/data/crows_pairs_anonymized.csv\"\n",
        "    print(f\"üì° Downloading from: {url}\")\n",
        "\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        csv_data = response.read().decode('utf-8')\n",
        "\n",
        "    df = pd.read_csv(io.StringIO(csv_data))\n",
        "    print(f\"‚úÖ Successfully loaded {len(df)} bias examples from CrowS-Pairs!\")\n",
        "\n",
        "    # Convert to our format\n",
        "    crows_full = []\n",
        "    for _, row in df.iterrows():\n",
        "        crows_full.append({\n",
        "            'stereotype': row['sent_more'],\n",
        "            'anti_stereotype': row['sent_less'],\n",
        "            'bias_type': row['bias_type']\n",
        "        })\n",
        "\n",
        "    # Split into train/eval (80/20)\n",
        "    split_idx = int(len(crows_full) * 0.8)\n",
        "    crows_train = crows_full[:split_idx]\n",
        "    crows_eval = crows_full[split_idx:]\n",
        "\n",
        "    print(f\"üìä Training examples: {len(crows_train)}\")\n",
        "    print(f\"üìä Evaluation examples: {len(crows_eval)}\")\n",
        "    print(f\"üìä Bias types present: {df['bias_type'].unique().tolist()}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Failed to download CrowS-Pairs: {e}\")\n",
        "    print(f\"   Falling back to built-in 31 pairs\")\n",
        "\n",
        "    # Fallback to built-in pairs\n",
        "    split_idx = int(len(bias_pairs) * 0.8)\n",
        "    crows_train = bias_pairs[:split_idx]\n",
        "    crows_eval = bias_pairs[split_idx:]\n",
        "    print(f\"üìä Training examples: {len(crows_train)}\")\n",
        "    print(f\"üìä Evaluation examples: {len(crows_eval)}\")\n",
        "    print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "ca720b83",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "01c80f9d",
      "cell_type": "code",
      "source": [
        "class ContrastivePLLTrainer:\n",
        "    \"\"\"Trains model to minimize (PLL_stereo - PLL_anti)^2 to achieve neutral 50% bias\"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer, device, learning_rate=1e-5):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    def pll_score_with_grad(self, model, text):\n",
        "        \"\"\"Compute pseudo-log-likelihood score (with gradients enabled)\"\"\"\n",
        "        tokens = self.tokenizer.encode(text, add_special_tokens=True)\n",
        "        if len(tokens) <= 2:  # Only [CLS] and [SEP]\n",
        "            return torch.tensor(0.0, device=self.device)\n",
        "\n",
        "        total_pll = torch.tensor(0.0, device=self.device, requires_grad=True)\n",
        "        count = 0\n",
        "\n",
        "        for i in range(1, len(tokens) - 1):  # Skip [CLS] and [SEP]\n",
        "            masked_tokens = tokens.copy()\n",
        "            original_token = masked_tokens[i]\n",
        "            masked_tokens[i] = self.tokenizer.mask_token_id\n",
        "\n",
        "            input_ids = torch.tensor([masked_tokens], device=self.device)\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(input_ids)\n",
        "                logits = outputs.logits\n",
        "                log_probs = torch.log_softmax(logits[0, i], dim=-1)\n",
        "                token_pll = log_probs[original_token]\n",
        "                total_pll = total_pll + token_pll\n",
        "                count += 1\n",
        "\n",
        "        return total_pll / count if count > 0 else torch.tensor(0.0, device=self.device)\n",
        "\n",
        "    def train_epoch(self, pairs):\n",
        "        self.model.train()\n",
        "        epoch_losses = []\n",
        "\n",
        "        for pair in tqdm(pairs, desc=\"Contrastive PLL Training\"):\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # Compute PLL for both sentences\n",
        "            pll_stereo = self.pll_score_with_grad(self.model, pair['stereotype'])\n",
        "            pll_anti = self.pll_score_with_grad(self.model, pair['anti_stereotype'])\n",
        "\n",
        "            # Loss: push both PLLs to be equal (difference should be 0)\n",
        "            loss = (pll_stereo - pll_anti) ** 2\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "        return np.mean(epoch_losses)\n",
        "\n",
        "print(\"‚úÖ Contrastive PLL trainer defined\")\n"
      ],
      "metadata": {
        "id": "01c80f9d",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "63d2d6ab",
      "cell_type": "code",
      "source": [
        "# print(\"=\"*60)\n",
        "# print(\"AGGRESSIVE CONTRASTIVE PLL TRAINING\")\n",
        "# print(\"=\"*60)\n",
        "\n",
        "# # Force GPU usage\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device('cuda')\n",
        "#     print(f\"GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
        "#     print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "# else:\n",
        "#     device = torch.device('cpu')\n",
        "#     print(\"WARNING: Running on CPU - this will be slow!\")\n",
        "\n",
        "# # Create fresh model with adapter\n",
        "# contrastive_base = BertForMaskedLM.from_pretrained('bert-base-uncased').to(device)\n",
        "# contrastive_adapter = DebiasAdapter(768, ADAPTER_SIZE).to(device)\n",
        "\n",
        "# class AdaptedMLM(nn.Module):\n",
        "#     def __init__(self, base, adapter):\n",
        "#         super().__init__()\n",
        "#         self.base = base\n",
        "#         self.adapter = adapter\n",
        "#         # Freeze base model\n",
        "#         for param in self.base.parameters():\n",
        "#             param.requires_grad = False\n",
        "\n",
        "#     def forward(self, input_ids):\n",
        "#         outputs = self.base.bert(input_ids)\n",
        "#         hidden = outputs.last_hidden_state\n",
        "#         adapted = self.adapter(hidden)\n",
        "#         logits = self.base.cls(adapted)\n",
        "#         return type('Outputs', (), {'logits': logits})()\n",
        "\n",
        "# contrastive_model = AdaptedMLM(contrastive_base, contrastive_adapter).to(device)\n",
        "\n",
        "# # Use aggressive training schedule\n",
        "# CONTRASTIVE_EPOCHS = 5\n",
        "# CONTRASTIVE_LR = 5e-5     # Higher learning rate for faster convergence\n",
        "\n",
        "# print(f\"Configuration:\")\n",
        "# print(f\"   Epochs: {CONTRASTIVE_EPOCHS}\")\n",
        "# print(f\"   Learning Rate: {CONTRASTIVE_LR}\")\n",
        "# print(f\"   Training pairs: {len(crows_train)}\")\n",
        "# print(f\"   Evaluation pairs: {len(crows_eval)}\")\n",
        "# print(f\"   Device: {device}\")\n",
        "\n",
        "# # Train\n",
        "# trainer = ContrastivePLLTrainer(contrastive_model, tokenizer, device, learning_rate=CONTRASTIVE_LR)\n",
        "# contrastive_losses = []\n",
        "\n",
        "# t0 = time.time()\n",
        "# for epoch in range(CONTRASTIVE_EPOCHS):\n",
        "#     avg_loss = trainer.train_epoch(crows_train)\n",
        "#     contrastive_losses.append(avg_loss)\n",
        "#     print(f\"Epoch {epoch+1}/{CONTRASTIVE_EPOCHS}: Avg Loss = {avg_loss:.4f}\")\n",
        "\n",
        "# training_time = time.time() - t0\n",
        "# print(f\"Training complete in {training_time:.1f}s\")\n",
        "# print(f\"   Loss: {contrastive_losses[0]:.4f} -> {contrastive_losses[-1]:.4f}\")\n",
        "# print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "63d2d6ab",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "pn101P-rlifL",
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"AGGRESSIVE CONTRASTIVE PLL TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Force GPU usage\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"WARNING: Running on CPU - this will be slow!\")\n",
        "\n",
        "# Create fresh model with adapter\n",
        "contrastive_base = BertForMaskedLM.from_pretrained('bert-base-uncased').to(device)\n",
        "contrastive_adapter = DebiasAdapter(768, ADAPTER_SIZE).to(device)\n",
        "\n",
        "\n",
        "# --- THIS CLASS IS NOW CORRECTED ---\n",
        "class AdaptedMLM(nn.Module):\n",
        "    def __init__(self, base, adapter):\n",
        "        super().__init__()\n",
        "        self.base = base\n",
        "        self.adapter = adapter\n",
        "        # Freeze base model\n",
        "        for param in self.base.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # --- FIX: Added 'attention_mask=None' and passed it to the model ---\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.base.bert(input_ids, attention_mask=attention_mask)\n",
        "        # ----------------------------------------------------------------\n",
        "\n",
        "        hidden = outputs.last_hidden_state\n",
        "        adapted = self.adapter(hidden)\n",
        "        logits = self.base.cls(adapted)\n",
        "        return type('Outputs', (), {'logits': logits})()\n",
        "# ---------------------------------\n",
        "\n",
        "contrastive_model = AdaptedMLM(contrastive_base, contrastive_adapter).to(device)\n",
        "\n",
        "# Use aggressive training schedule\n",
        "CONTRASTIVE_EPOCHS = 5\n",
        "CONTRASTIVE_LR = 5e-5      # Higher learning rate for faster convergence\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"   Epochs: {CONTRASTIVE_EPOCHS}\")\n",
        "print(f\"   Learning Rate: {CONTRASTIVE_LR}\")\n",
        "print(f\"   Training pairs: {len(crows_train)}\")\n",
        "print(f\"   Evaluation pairs: {len(crows_eval)}\")\n",
        "print(f\"   Device: {device}\")\n",
        "\n",
        "# Train\n",
        "trainer = ContrastivePLLTrainer(contrastive_model, tokenizer, device, learning_rate=CONTRASTIVE_LR)\n",
        "contrastive_losses = []\n",
        "\n",
        "t0 = time.time()\n",
        "for epoch in range(CONTRASTIVE_EPOCHS):\n",
        "    avg_loss = trainer.train_epoch(crows_train)\n",
        "    contrastive_losses.append(avg_loss)\n",
        "    print(f\"Epoch {epoch+1}/{CONTRASTIVE_EPOCHS}: Avg Loss = {avg_loss:.4f}\")\n",
        "\n",
        "training_time = time.time() - t0\n",
        "print(f\"Training complete in {training_time:.1f}s\")\n",
        "if contrastive_losses: # Avoid error if epochs = 0\n",
        "    print(f\"   Loss: {contrastive_losses[0]:.4f} -> {contrastive_losses[-1]:.4f}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "pn101P-rlifL",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "62CBJQKL63Tm",
      "cell_type": "code",
      "source": [
        "# Quality evaluation: perplexity on neutral sentences\n",
        "neutral_sentences = [\n",
        "    \"The weather is nice today.\",\n",
        "    \"I enjoy reading books in my free time.\",\n",
        "    \"The meeting is scheduled for tomorrow morning.\",\n",
        "    \"She bought groceries from the store.\",\n",
        "    \"Technology has changed how we communicate.\",\n",
        "    \"The restaurant serves delicious food.\",\n",
        "    \"He enjoys playing sports on weekends.\",\n",
        "    \"The movie was entertaining and well-made.\",\n",
        "    \"They traveled to several countries last year.\",\n",
        "    \"Coffee helps me stay awake in the morning.\",\n",
        "]\n",
        "\n",
        "def compute_perplexity(model, tokenizer, sentences, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "    criterion = nn.CrossEntropyLoss(reduction='sum', ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sent in sentences:\n",
        "            inputs = tokenizer(sent, return_tensors='pt', truncation=True, max_length=64)\n",
        "            input_ids = inputs['input_ids'].to(device)\n",
        "            attention_mask = inputs.get('attention_mask', torch.ones_like(input_ids)).to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "\n",
        "            # Shift for autoregressive loss\n",
        "            shift_logits = logits[:, :-1, :].contiguous()\n",
        "            shift_labels = input_ids[:, 1:].contiguous()\n",
        "\n",
        "            loss = criterion(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "            total_loss += loss.item()\n",
        "            total_tokens += (shift_labels != tokenizer.pad_token_id).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / total_tokens if total_tokens > 0 else 0\n",
        "    perplexity = np.exp(avg_loss)\n",
        "    return perplexity\n",
        "\n",
        "print(\"‚úÖ Perplexity function and neutral sentences defined.\")"
      ],
      "metadata": {
        "id": "62CBJQKL63Tm",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "FiOwT0eO7ZgO",
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "from typing import List, Tuple, Dict\n",
        "import warnings\n",
        "from collections import defaultdict # Added for eval function\n",
        "import torch.optim as optim # Added for PLL trainer\n",
        "from torch.utils.data import Dataset, DataLoader # Added for PLL trainer\n",
        "import random # Added for PLL trainer\n",
        "import urllib.request # Added for data download\n",
        "import io # Added for data download\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# FORCE GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"‚úÖ Device set to: {device}\")\n",
        "    torch.cuda.empty_cache()\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"WARNING: Running on CPU - this will be slow!\")\n",
        "\n",
        "# Hyperparameters (GPU-optimized)\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 5\n",
        "LEARNING_RATE = 3e-4\n",
        "TEMPERATURE = 0.05\n",
        "ADAPTER_SIZE = 256\n",
        "TRAIN_SAMPLE = 5\n",
        "\n",
        "# --- THIS IS THE FIX FOR 'comp_df' not defined ---\n",
        "comp_df = pd.DataFrame()\n",
        "trained_models = {}\n",
        "# ---------------------------------------------\n",
        "\n",
        "# Load tokenizer for global use\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "print(f\"\\nTokenizer loaded: bert-base-uncased\")"
      ],
      "metadata": {
        "id": "FiOwT0eO7ZgO",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "h1SObPhYmZNS",
      "cell_type": "code",
      "source": [
        "# Evaluate contrastive model\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä EVALUATING CONTRASTIVE MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "trainer.model.eval()\n",
        "\n",
        "# --- MODIFIED FOR COMPARABLE RESULTS ---\n",
        "# We are now evaluating on the *full* 'crows_eval' set, just like the baseline.\n",
        "print(f\"\\n‚è≥ Evaluating trained model on all {len(crows_eval)} evaluation pairs...\")\n",
        "contrastive_results = evaluate_on_crows_pairs(trainer.model, tokenizer, crows_eval, device)\n",
        "# -------------------------------------\n",
        "\n",
        "print(\"‚è≥ Computing perplexity on neutral sentences...\")\n",
        "contrastive_ppl = compute_perplexity(trainer.model, tokenizer, neutral_sentences, device)\n",
        "\n",
        "contrastive_overall = contrastive_results['preference'] * 100.0\n",
        "\n",
        "print(f\"\\nüéØ Contrastive PLL Results:\")\n",
        "print(f\"   Overall Bias: {contrastive_overall:.2f}%\")\n",
        "print(f\"   Target: 50.0% (neutral)\")\n",
        "print(f\"   Distance from target: {abs(contrastive_overall - 50.0):.2f}pp\")\n",
        "print(f\"   Perplexity: {contrastive_ppl:.2f}\")\n",
        "\n",
        "print(f\"\\nüìã By Category:\")\n",
        "for bias_type, scores in sorted(contrastive_results['by_type'].items()):\n",
        "    pref = scores['preference'] * 100.0\n",
        "    total = scores['total']\n",
        "    indicator = \"üü¢\" if pref < 60 else \"üü°\" if pref < 70 else \"üî¥\"\n",
        "    print(f\"   {indicator} {bias_type.capitalize()}: {pref:.1f}% ({total} pairs)\")\n",
        "\n",
        "# Add to comparison\n",
        "contrastive_row = {\n",
        "    'name': 'contrastive_pll',\n",
        "    'type': 'contrastive',\n",
        "    'trainable_params': sum(p.numel() for p in trainer.model.parameters() if p.requires_grad),\n",
        "    'overall_pref': contrastive_overall,\n",
        "    'perplexity': contrastive_ppl,\n",
        "    'time_sec': 0  # Not tracked in detail\n",
        "}\n",
        "for k,v in contrastive_results['by_type'].items():\n",
        "    contrastive_row[f\"cat_{k}\"] = v['preference'] * 100.0\n",
        "\n",
        "comp_df = pd.concat([comp_df, pd.DataFrame([contrastive_row])], ignore_index=True)\n",
        "trained_models['contrastive_pll'] = trainer.model\n",
        "\n",
        "print(\"\\n‚úÖ Added to comparison table\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "h1SObPhYmZNS",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "GJO1x2Cn8JeW",
      "cell_type": "code",
      "source": [
        "torch.save(contrastive_adapter.state_dict(), \"/content/saved_models/adapter_only.pt\")\n"
      ],
      "metadata": {
        "id": "GJO1x2Cn8JeW",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "u0FUVueUHbMH",
      "cell_type": "markdown",
      "source": [
        "## BASELINE BERT + crowspair"
      ],
      "metadata": {
        "id": "u0FUVueUHbMH"
      }
    },
    {
      "id": "KMZGl1YNHfe0",
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üìä RE-EVALUATING BASELINE on CrowS-Pairs Eval Set\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 'base_model' was loaded in Cell 11\n",
        "# 'crows_eval' was loaded in Cell 24\n",
        "\n",
        "base_model.to(device)\n",
        "base_model.eval()\n",
        "\n",
        "# Evaluate on the *same* 302-pair set used for the final experiment\n",
        "crows_baseline_results = evaluate_on_crows_pairs(base_model, tokenizer, crows_eval, device)\n",
        "\n",
        "crows_baseline_pref = crows_baseline_results['preference'] * 100\n",
        "print(f\"\\nüéØ True Baseline Stereotype Preference (on CrowS-Pairs Eval): {crows_baseline_pref:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "KMZGl1YNHfe0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dda24664-0c9b-49ca-8258-2c2c178972f7",
      "cell_type": "markdown",
      "source": [
        "# expt 2 : downstream with jz adapter 1 (failed)"
      ],
      "metadata": {
        "id": "dda24664-0c9b-49ca-8258-2c2c178972f7"
      }
    },
    {
      "id": "b0be1a9b-ae94-4e5d-bee3-ab623995e0cf",
      "cell_type": "code",
      "source": [
        "# --- Step 1: Install Requirements (Run this first if needed) ---\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "\n",
        "# Setup Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 2. Load Real BiasBios Dataset ---\n",
        "class RealBiasBiosDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, split='train', max_samples=None):\n",
        "        try:\n",
        "            # Load from Hugging Face\n",
        "            dataset = load_dataset(\"LabHC/bias_in_bios\", split=split)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading dataset: {e}. Try '!pip install datasets'\")\n",
        "            return\n",
        "\n",
        "        # Subsample for speed (optional)\n",
        "        if max_samples is not None and max_samples < len(dataset):\n",
        "            dataset = dataset.select(range(max_samples))\n",
        "\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Profession ID Mapping\n",
        "        self.label_map = {\n",
        "            0: 'accountant', 1: 'architect', 2: 'attorney', 3: 'chiropractor',\n",
        "            4: 'comedian', 5: 'composer', 6: 'dentist', 7: 'dietitian',\n",
        "            8: 'dj', 9: 'filmmaker', 10: 'interior_designer', 11: 'journalist',\n",
        "            12: 'model', 13: 'nurse', 14: 'painter', 15: 'paralegal',\n",
        "            16: 'pastor', 17: 'personal_trainer', 18: 'photographer', 19: 'physician',\n",
        "            20: 'poet', 21: 'professor', 22: 'psychologist', 23: 'rapper',\n",
        "            24: 'software_engineer', 25: 'surgeon', 26: 'teacher', 27: 'yoga_teacher'\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        text = item['hard_text']\n",
        "        label = item['profession']\n",
        "        gender = item['gender'] # 0=Male, 1=Female\n",
        "\n",
        "        inputs = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
        "            'label': torch.tensor(label),\n",
        "            'gender': torch.tensor(gender)\n",
        "        }\n",
        "\n",
        "# --- 3. Model Definition ---\n",
        "class DebiasAdapter(nn.Module):\n",
        "    def __init__(self, hidden_size=768, adapter_size=256):\n",
        "        super().__init__()\n",
        "        self.adapter = nn.Sequential(\n",
        "            nn.Linear(hidden_size, adapter_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(adapter_size, hidden_size),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "    def forward(self, hidden_states):\n",
        "        return hidden_states + self.adapter(hidden_states)\n",
        "\n",
        "class AdaptedBERT(nn.Module):\n",
        "    def __init__(self, base_model_name='bert-base-uncased', adapter_size=256):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(base_model_name)\n",
        "        self.adapter = DebiasAdapter(768, adapter_size)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        last_hidden = outputs.last_hidden_state\n",
        "        adapted = self.adapter(last_hidden)\n",
        "        return adapted[:, 0, :]\n",
        "\n",
        "class BiasClassifier(nn.Module):\n",
        "    def __init__(self, backbone, num_labels=28, freeze_backbone=True):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.classifier = nn.Linear(768, num_labels)\n",
        "\n",
        "        if freeze_backbone:\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        embeddings = self.backbone(input_ids, attention_mask)\n",
        "        return self.classifier(embeddings)\n",
        "\n",
        "# --- 4. Metrics & Training ---\n",
        "def calculate_metrics(y_true, y_pred, genders, label_map):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    classes = np.unique(y_true)\n",
        "    gaps = []\n",
        "\n",
        "    for cls in classes:\n",
        "        m_mask = (genders == 0) & (y_true == cls)\n",
        "        f_mask = (genders == 1) & (y_true == cls)\n",
        "\n",
        "        if m_mask.sum() == 0 or f_mask.sum() == 0: continue\n",
        "\n",
        "        m_tpr = (y_pred[m_mask] == cls).sum() / m_mask.sum()\n",
        "        f_tpr = (y_pred[f_mask] == cls).sum() / f_mask.sum()\n",
        "\n",
        "        gaps.append(abs(m_tpr - f_tpr))\n",
        "\n",
        "    avg_tpr_gap = np.mean(gaps) if gaps else 0.0\n",
        "    return acc, avg_tpr_gap\n",
        "\n",
        "def train_and_evaluate(model_name, model, train_loader, test_loader, epochs=3):\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.to(device)\n",
        "\n",
        "    print(f\"\\nüöÄ Training {model_name}...\")\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits = model(input_ids, mask)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    preds_all, labels_all, genders_all = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            logits = model(input_ids, mask)\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "            preds_all.extend(preds)\n",
        "            labels_all.extend(batch['label'].numpy())\n",
        "            genders_all.extend(batch['gender'].numpy())\n",
        "\n",
        "    acc, gap = calculate_metrics(np.array(labels_all), np.array(preds_all), np.array(genders_all), train_loader.dataset.label_map)\n",
        "    print(f\"   > Accuracy: {acc:.4f}\")\n",
        "    print(f\"   > TPR-Gap:  {gap:.4f}\")\n",
        "    return acc, gap\n",
        "\n",
        "# --- 5. Execution ---\n",
        "# Prepare Data\n",
        "print(\"‚è≥ Loading Data...\")\n",
        "train_set = RealBiasBiosDataset(split='train', max_samples=5000)\n",
        "test_set = RealBiasBiosDataset(split='test', max_samples=1000)\n",
        "\n",
        "if hasattr(train_set, 'dataset'):\n",
        "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=32)\n",
        "\n",
        "    # A. Baseline Run\n",
        "    baseline_backbone = AdaptedBERT()\n",
        "    baseline_model = BiasClassifier(baseline_backbone, freeze_backbone=True)\n",
        "    base_acc, base_gap = train_and_evaluate(\"Baseline BERT\", baseline_model, train_loader, test_loader)\n",
        "\n",
        "    # B. Ours (Debiased) Run\n",
        "    our_backbone = AdaptedBERT()\n",
        "\n",
        "    # *** KAGGLE PATH FIX ***\n",
        "    # If you just ran training, the file is here:\n",
        "    adapter_path = \"/kaggle/input/peft-1/adapter_only.pt\"\n",
        "    # If you uploaded it as a dataset, it might be: \"../input/your-dataset/adapter_only.pt\"\n",
        "\n",
        "    if os.path.exists(adapter_path):\n",
        "        print(f\"\\n‚úÖ Found adapter at: {adapter_path}\")\n",
        "        our_backbone.adapter.load_state_dict(torch.load(adapter_path, map_location=device))\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è Adapter not found at {adapter_path}. Using random weights (results will be invalid).\")\n",
        "\n",
        "    our_model = BiasClassifier(our_backbone, freeze_backbone=True)\n",
        "    our_acc, our_gap = train_and_evaluate(\"Debiased Adapter\", our_model, train_loader, test_loader)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"üèÜ FINAL RESULTS\")\n",
        "    print(f\"{'Model':<20} | {'Accuracy':<10} | {'TPR-Gap':<10}\")\n",
        "    print(\"-\" * 45)\n",
        "    print(f\"{'Baseline':<20} | {base_acc:.4f}     | {base_gap:.4f}\")\n",
        "    print(f\"{'Ours':<20} | {our_acc:.4f}     | {our_gap:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "b0be1a9b-ae94-4e5d-bee3-ab623995e0cf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "637d05d3-630c-447a-a9ca-7ccd858d8165",
      "cell_type": "markdown",
      "source": [
        "### RESULTS\n",
        "---\n",
        "\n",
        "Using device: cuda<br>\n",
        "‚è≥ Loading Data...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "<br>\n",
        "üöÄ Training Baseline BERT...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "   > Accuracy: 0.6880<br>\n",
        "   > TPR-Gap:  0.2013<br>\n",
        "<br>\n",
        "‚úÖ Found adapter at: /kaggle/input/peft-1/adapter_only.pt<br>\n",
        "<br>\n",
        "üöÄ Training Debiased Adapter...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "Loading widget...<br>\n",
        "   > Accuracy: 0.6860<br>\n",
        "   > TPR-Gap:  0.2268<br>\n",
        "<br>\n",
        "========================================<br>\n",
        "üèÜ FINAL RESULTS<br>\n",
        "Model                | Accuracy   | TPR-Gap   <br>\n",
        "---------------------------------------------<br>\n",
        "Baseline             | 0.6880     | 0.2013<br>\n",
        "Ours                 | 0.6860     | 0.2268     \n"
      ],
      "metadata": {
        "id": "637d05d3-630c-447a-a9ca-7ccd858d8165"
      }
    },
    {
      "id": "d7c4933c-e3f9-4d44-9c19-053798839429",
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana; line-height: 1.7em;\">\n",
        "    üìå &nbsp; last experiment (the BiasBios one) gave us a crucial insight: your DebiasAdapter (a simple bottleneck) is great at reducing intrinsic bias (the CrowS score) but fails to transfer that fairness to a downstream task (the TPR-GAP went up to 0.2268).\n",
        "</div>"
      ],
      "metadata": {
        "id": "d7c4933c-e3f9-4d44-9c19-053798839429"
      }
    },
    {
      "id": "4d1c8fb3-d8a8-492d-827a-60d4f6d657ae",
      "cell_type": "markdown",
      "source": [
        "Block 1: Setup, Imports & Data Loading"
      ],
      "metadata": {
        "id": "4d1c8fb3-d8a8-492d-827a-60d4f6d657ae"
      }
    },
    {
      "id": "yc5U02KvJ2tg",
      "cell_type": "code",
      "source": [
        "# --- 1. Install & Imports ---\n",
        "!pip install -q -U adapters datasets\n",
        "print(\"adapters installed\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, BertForMaskedLM\n",
        "from adapters import AutoAdapterModel, LoRAConfig, PrefixTuningConfig\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import urllib.request\n",
        "import io\n",
        "\n",
        "# Setup Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"‚úÖ Using device: {device}\")\n",
        "\n",
        "# --- 2. Load CrowS-Pairs Data ---\n",
        "print(\"\\nüì• Loading CrowS-Pairs Dataset...\")\n",
        "url = \"https://raw.githubusercontent.com/nyu-mll/crows-pairs/master/data/crows_pairs_anonymized.csv\"\n",
        "with urllib.request.urlopen(url) as response:\n",
        "    df = pd.read_csv(io.StringIO(response.read().decode('utf-8')))\n",
        "\n",
        "crows_full = []\n",
        "for _, row in df.iterrows():\n",
        "    crows_full.append({\n",
        "        'stereotype': row['sent_more'],\n",
        "        'anti_stereotype': row['sent_less'],\n",
        "        'bias_type': row['bias_type']\n",
        "    })\n",
        "\n",
        "# Split 80/20\n",
        "split_idx = int(len(crows_full) * 0.8)\n",
        "crows_train = crows_full[:split_idx]\n",
        "crows_eval = crows_full[split_idx:]\n",
        "print(f\"‚úÖ Loaded {len(crows_train)} training and {len(crows_eval)} evaluation pairs.\")\n",
        "\n",
        "# --- 3. Load Tokenizer ---\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# --- 4. Define Contrastive PLL Trainer ---\n",
        "class ContrastivePLLTrainer:\n",
        "    def __init__(self, model, tokenizer, device, learning_rate=1e-4):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        # Optimized for PEFT: Update only trainable params\n",
        "        self.optimizer = torch.optim.AdamW(\n",
        "            [p for p in model.parameters() if p.requires_grad],\n",
        "            lr=learning_rate\n",
        "        )\n",
        "\n",
        "    def pll_score_with_grad(self, text):\n",
        "        tokens = self.tokenizer.encode(text, add_special_tokens=True)\n",
        "        if len(tokens) <= 2: return torch.tensor(0.0, device=self.device)\n",
        "\n",
        "        total_pll = torch.tensor(0.0, device=self.device, requires_grad=True)\n",
        "        count = 0\n",
        "\n",
        "        # Create batch of masked inputs for efficiency\n",
        "        input_ids_list = []\n",
        "        target_ids_list = []\n",
        "\n",
        "        for i in range(1, len(tokens) - 1):\n",
        "            masked = tokens.copy()\n",
        "            target = masked[i]\n",
        "            masked[i] = self.tokenizer.mask_token_id\n",
        "            input_ids_list.append(masked)\n",
        "            target_ids_list.append(target)\n",
        "\n",
        "        if not input_ids_list: return torch.tensor(0.0, device=self.device)\n",
        "\n",
        "        input_tensor = torch.tensor(input_ids_list, device=self.device)\n",
        "        target_tensor = torch.tensor(target_ids_list, device=self.device)\n",
        "\n",
        "        outputs = self.model(input_tensor)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Gather correct log-probs\n",
        "        # shape: [batch, seq_len, vocab] -> [batch, vocab] at masked positions\n",
        "        # We need indices 1 to len(tokens)-1 matching the batch items\n",
        "        range_indices = torch.arange(1, len(tokens) - 1, device=self.device)\n",
        "\n",
        "        # Extract logits for the specific masked tokens\n",
        "        # Since input_tensor[k] has mask at index k+1, we gather from that index\n",
        "        target_logits = logits[torch.arange(len(input_ids_list)), range_indices]\n",
        "        log_probs = F.log_softmax(target_logits, dim=-1)\n",
        "\n",
        "        token_plls = log_probs.gather(1, target_tensor.unsqueeze(1)).squeeze()\n",
        "        return token_plls.mean()\n",
        "\n",
        "    def train_epoch(self, pairs):\n",
        "        self.model.train()\n",
        "        epoch_losses = []\n",
        "\n",
        "        # Shuffle pairs\n",
        "        np.random.shuffle(pairs)\n",
        "\n",
        "        for pair in tqdm(pairs, desc=\"Training\", leave=False):\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            pll_stereo = self.pll_score_with_grad(pair['stereotype'])\n",
        "            pll_anti = self.pll_score_with_grad(pair['anti_stereotype'])\n",
        "\n",
        "            # Contrastive Loss: Minimize squared difference\n",
        "            loss = (pll_stereo - pll_anti) ** 2\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "        return np.mean(epoch_losses)\n",
        "\n",
        "# --- 5. Evaluation Helpers ---\n",
        "def compute_pll(model, text):\n",
        "    # Simple PLL for evaluation (no grad)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        score = 0.0\n",
        "        tokens = inputs.input_ids[0]\n",
        "        for i in range(1, len(tokens)-1):\n",
        "            tmp = tokens.clone()\n",
        "            tmp[i] = tokenizer.mask_token_id\n",
        "            out = model(tmp.unsqueeze(0))\n",
        "            score += F.log_softmax(out.logits[0, i], dim=-1)[tokens[i]].item()\n",
        "    return score / (len(tokens)-2) if len(tokens) > 2 else 0.0\n",
        "\n",
        "def evaluate_bias(model, eval_pairs):\n",
        "    model.eval()\n",
        "    stereo_wins = 0\n",
        "    for p in tqdm(eval_pairs, desc=\"Evaluating Bias\"):\n",
        "        s_score = compute_pll(model, p['stereotype'])\n",
        "        a_score = compute_pll(model, p['anti_stereotype'])\n",
        "        if s_score > a_score: stereo_wins += 1\n",
        "    return (stereo_wins / len(eval_pairs)) * 100\n",
        "\n",
        "neutral_sents = [\n",
        "    \"The weather is nice today.\", \"I enjoy reading books.\",\n",
        "    \"The sun rises in the east.\", \"Technology is changing fast.\",\n",
        "    \"She walked to the store.\", \"He cooked dinner for friends.\"\n",
        "]\n",
        "\n",
        "def evaluate_perplexity(model):\n",
        "    model.eval()\n",
        "    total_nll = 0\n",
        "    count = 0\n",
        "    for sent in neutral_sents:\n",
        "        nll = -compute_pll(model, sent)\n",
        "        total_nll += nll\n",
        "        count += 1\n",
        "    return np.exp(total_nll / count)"
      ],
      "metadata": {
        "id": "yc5U02KvJ2tg",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9075895e-a5f2-4647-8bf5-9cf3a3f4cf4e",
      "cell_type": "markdown",
      "source": [
        "Block 2: Run LoRA Experiment\n",
        "This builds, trains, and evaluates the LoRA version."
      ],
      "metadata": {
        "id": "9075895e-a5f2-4647-8bf5-9cf3a3f4cf4e"
      }
    },
    {
      "id": "741c960d-6a00-44d5-a951-e4f6213c808b",
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"ü•ä ROUND 1: LoRA Architecture\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# 1. Setup Model\n",
        "lora_model = AutoAdapterModel.from_pretrained(\"bert-base-uncased\")\n",
        "lora_config = LoRAConfig(r=8, alpha=16)\n",
        "lora_model.add_adapter(\"lora_debias\", config=lora_config)\n",
        "lora_model.train_adapter(\"lora_debias\")\n",
        "lora_model.add_masked_lm_head(\"lora_debias\")\n",
        "lora_model.to(device)\n",
        "\n",
        "print(f\"‚úÖ Model Ready. Trainable Params: {sum(p.numel() for p in lora_model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "# 2. Train\n",
        "print(\"‚è≥ Training LoRA (5 Epochs)...\")\n",
        "lora_trainer = ContrastivePLLTrainer(lora_model, tokenizer, device, learning_rate=3e-4)\n",
        "for ep in range(5):\n",
        "    loss = lora_trainer.train_epoch(crows_train)\n",
        "    print(f\"   Epoch {ep+1}: Loss = {loss:.4f}\")\n",
        "\n",
        "# 3. Save & Evaluate\n",
        "lora_model.save_adapter(\"/kaggle/working/lora_debias\", \"lora_debias\")\n",
        "lora_bias = evaluate_bias(lora_model, crows_eval)\n",
        "lora_ppl = evaluate_perplexity(lora_model)\n",
        "\n",
        "print(f\"\\nüìä LoRA Results:\")\n",
        "print(f\"   Bias Score: {lora_bias:.2f}% (Target: 50%)\")\n",
        "print(f\"   Perplexity: {lora_ppl:.2f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "741c960d-6a00-44d5-a951-e4f6213c808b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ff4e3729-3df0-4585-b250-b32307de785b",
      "cell_type": "markdown",
      "source": [
        "Block 3: Run Prompt Tuning Experiment\n",
        "This builds, trains, and evaluates the Prompt Tuning version."
      ],
      "metadata": {
        "id": "ff4e3729-3df0-4585-b250-b32307de785b"
      }
    },
    {
      "id": "3818409d-5b1d-4336-add2-df70157e7082",
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"ü•ä ROUND 2: Prompt Tuning Architecture\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# 1. Setup Model\n",
        "prompt_model = AutoAdapterModel.from_pretrained(\"bert-base-uncased\")\n",
        "# prefix_length=20 adds 20 virtual tokens\n",
        "prompt_config = PrefixTuningConfig(flat=False, prefix_length=20)\n",
        "prompt_model.add_adapter(\"prompt_debias\", config=prompt_config)\n",
        "prompt_model.train_adapter(\"prompt_debias\")\n",
        "prompt_model.add_masked_lm_head(\"prompt_debias\")\n",
        "prompt_model.to(device)\n",
        "\n",
        "print(f\"‚úÖ Model Ready. Trainable Params: {sum(p.numel() for p in prompt_model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "# 2. Train (Note Higher Learning Rate for Prompts)\n",
        "print(\"‚è≥ Training Prompt Tuning (5 Epochs)...\")\n",
        "prompt_trainer = ContrastivePLLTrainer(prompt_model, tokenizer, device, learning_rate=1e-2)\n",
        "for ep in range(5):\n",
        "    loss = prompt_trainer.train_epoch(crows_train)\n",
        "    print(f\"   Epoch {ep+1}: Loss = {loss:.4f}\")\n",
        "\n",
        "# 3. Save & Evaluate\n",
        "prompt_model.save_adapter(\"/kaggle/working/prompt_debias\", \"prompt_debias\")\n",
        "prompt_bias = evaluate_bias(prompt_model, crows_eval)\n",
        "prompt_ppl = evaluate_perplexity(prompt_model)\n",
        "\n",
        "print(f\"\\nüìä Prompt Tuning Results:\")\n",
        "print(f\"   Bias Score: {prompt_bias:.2f}% (Target: 50%)\")\n",
        "print(f\"   Perplexity: {prompt_ppl:.2f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "3818409d-5b1d-4336-add2-df70157e7082"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "18943a3a-1364-4c0f-9900-024afcd2eccd",
      "cell_type": "markdown",
      "source": [
        "Block 4: Final Showdown Table"
      ],
      "metadata": {
        "id": "18943a3a-1364-4c0f-9900-024afcd2eccd"
      }
    },
    {
      "id": "a97b8157-fed0-4028-80b8-e22535754d31",
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üèÜ PEFT ARCHITECTURE SHOWDOWN: FINAL RESULTS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"{'Architecture':<20} | {'Bias % (Target 50)':<20} | {'Perplexity':<15}\")\n",
        "print(\"-\" * 60)\n",
        "# Assuming your Custom Adapter score from previous run was around 52%\n",
        "print(f\"{'Custom Adapter':<20} | {'~52.00 (Ref)':<20} | {'~15.5 (Ref)':<15}\")\n",
        "print(f\"{'LoRA':<20} | {lora_bias:<20.2f} | {lora_ppl:<15.2f}\")\n",
        "print(f\"{'Prompt Tuning':<20} | {prompt_bias:<20.2f} | {prompt_ppl:<15.2f}\")\n",
        "print(\"-\" * 60)"
      ],
      "metadata": {
        "trusted": true,
        "id": "a97b8157-fed0-4028-80b8-e22535754d31"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f5dba450-3d4c-4241-ab82-e8421a78eeb0",
      "cell_type": "markdown",
      "source": [
        "Block 5: Visualization Code"
      ],
      "metadata": {
        "id": "f5dba450-3d4c-4241-ab82-e8421a78eeb0"
      }
    },
    {
      "id": "433c4b33-b2a3-45b5-8f89-8f2515850926",
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- 1. Plot Training Loss Curves ---\n",
        "def plot_training_comparison(lora_losses, prompt_losses):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    epochs = range(1, len(lora_losses) + 1)\n",
        "\n",
        "    # Plot LoRA\n",
        "    plt.plot(epochs, lora_losses, 'o-', linewidth=2, label='LoRA (Weights)', color='#1f77b4')\n",
        "\n",
        "    # Plot Prompt Tuning\n",
        "    plt.plot(epochs, prompt_losses, 's--', linewidth=2, label='Prompt Tuning (Activations)', color='#ff7f0e')\n",
        "\n",
        "    plt.title('PEFT Training Dynamics: LoRA vs. Prompt Tuning', fontsize=14)\n",
        "    plt.xlabel('Epochs', fontsize=12)\n",
        "    plt.ylabel('Contrastive PLL Loss', fontsize=12)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/kaggle/working/loss_comparison.png\")\n",
        "    plt.show()\n",
        "\n",
        "# Run the plotter (assuming you have these lists from the previous steps)\n",
        "if 'lora_losses' in locals() and 'prompt_losses' in locals():\n",
        "    plot_training_comparison(lora_losses, prompt_losses)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Training loss lists not found. Did you run the training blocks?\")\n",
        "\n",
        "# --- 2. Plot The \"Pareto Frontier\" (Bias vs. Utility) ---\n",
        "def plot_tradeoff(results):\n",
        "    \"\"\"\n",
        "    results: dict like {'Model Name': (Bias_Score, Perplexity)}\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Define reference lines\n",
        "    plt.axvline(x=50, color='gray', linestyle='--', alpha=0.5, label='Ideal Neutrality (50%)')\n",
        "\n",
        "    colors = ['#2ca02c', '#1f77b4', '#ff7f0e'] # Green, Blue, Orange\n",
        "    markers = ['*', 'o', 's']\n",
        "\n",
        "    for i, (name, (bias, ppl)) in enumerate(results.items()):\n",
        "        plt.scatter(bias, ppl, s=200, color=colors[i], marker=markers[i], label=name, edgecolors='black')\n",
        "        # Annotate\n",
        "        plt.annotate(f\"{name}\\n({bias:.1f}%, {ppl:.1f})\",\n",
        "                     (bias, ppl),\n",
        "                     xytext=(10, 10), textcoords='offset points',\n",
        "                     fontsize=11)\n",
        "\n",
        "    plt.title('The Fairness-Utility Tradeoff', fontsize=16)\n",
        "    plt.xlabel('Stereotype Preference (Closer to 50% is better)', fontsize=12)\n",
        "    plt.ylabel('Perplexity (Lower is better)', fontsize=12)\n",
        "    plt.xlim(40, 80) # Zoom in on the relevant bias range\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"/kaggle/working/tradeoff_plot.png\")\n",
        "    plt.show()\n",
        "\n",
        "# Example Data (Replace these with your actual variables!)\n",
        "# Baseline numbers usually ~58% bias, ~4.5 perplexity\n",
        "final_results = {\n",
        "    \"Baseline (No Debias)\": (58.3, 15.2),\n",
        "    \"LoRA\": (lora_bias, lora_ppl),\n",
        "    \"Prompt Tuning\": (prompt_bias, prompt_ppl)\n",
        "}\n",
        "\n",
        "plot_tradeoff(final_results)"
      ],
      "metadata": {
        "trusted": true,
        "id": "433c4b33-b2a3-45b5-8f89-8f2515850926"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6c6b7669-7058-43fe-a8e9-d36686f4bff5",
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana; line-height: 1.7em;\">\n",
        "    üìå &nbsp; Contrastive PLL reduces intrinsic bias while preserving fluency for adapter-style PEFTs; naive LoRA/prompt tuning collapses LM quality.‚Äù\n",
        "</div>"
      ],
      "metadata": {
        "id": "6c6b7669-7058-43fe-a8e9-d36686f4bff5"
      }
    },
    {
      "id": "27e3a04f-a65a-4c4c-b451-4425a2956ea9",
      "cell_type": "markdown",
      "source": [
        "## If wanna improve thiss previous one (expt 3)\n",
        "---\n",
        "\n",
        "You are right, that result is problematic. While the bias scores (45-47%) are technically low, the perplexity scores (53,000+ and 23,000+) mean the models have become **completely incoherent**. A usable language model should have a perplexity between 10 and 50.\n",
        "\n",
        "This is a classic case of **\"Catastrophic Forgetting\"** or **\"Model Collapse.\"** The model has learned to minimize the contrastive loss by outputting gibberish that is equally meaningless for both \"he\" and \"she,\" thus achieving a \"fair\" score of \\~50% bias but zero utility.\n",
        "\n",
        "### üö® What Went Wrong?\n",
        "\n",
        "The issue lies in the **loss function** vs. the **training method**.\n",
        "Your contrastive loss `(PLL_stereo - PLL_anti)^2` *only* cares about making the two probabilities equal. It does not punish the model for making *both* probabilities zero.\n",
        "\n",
        "  * **Custom Adapter (52% Bias, \\~15 Perplexity):** This worked because the adapter structure (bottleneck) and initialization naturally preserved the original BERT knowledge.\n",
        "  * **LoRA / Prompt Tuning (High Perplexity):** These methods, especially with the aggressive learning rates we tried (`1e-2` for prompts), allowed the optimization to drift too far from the original language manifold. The model found a \"hack\": destroy the language capability so `P(stereo) ‚âà P(anti) ‚âà 0`.\n",
        "\n",
        "### üõ†Ô∏è How to Fix This (The \"Regularization\" Fix)\n",
        "\n",
        "We need to add a **regularization term** to the loss function. We must tell the model: \"Make bias equal, BUT keep the probability of the sentence high.\"\n",
        "\n",
        "**New Loss Function:**\n",
        "$$L = (PLL_{stereo} - PLL_{anti})^2 - \\lambda \\cdot (PLL_{stereo} + PLL_{anti})$$\n",
        "\n",
        "  * **Term 1:** Minimize bias (make them equal).\n",
        "  * **Term 2:** Maximize likelihood (make them both high).\n",
        "  * **Lambda ($\\lambda$):** A weight to balance them (try 0.1 or 0.5).\n",
        "\n",
        "### ‚ö° Immediate Action Plan\n",
        "\n",
        "You don't need to scrap everything. Just modify the `train_epoch` function in your `ContrastivePLLTrainer` class and re-run the LoRA experiment (it's faster).\n",
        "\n",
        "**Copy-Paste this Updated Trainer Class:**\n",
        "\n",
        "```python\n",
        "class ContrastivePLLTrainer:\n",
        "    def __init__(self, model, tokenizer, device, learning_rate=1e-4, alpha=0.1):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.alpha = alpha # Regularization strength\n",
        "        self.optimizer = torch.optim.AdamW(\n",
        "            [p for p in model.parameters() if p.requires_grad],\n",
        "            lr=learning_rate\n",
        "        )\n",
        "\n",
        "    def pll_score_with_grad(self, text):\n",
        "        # ... (This method stays exactly the same as before) ...\n",
        "        tokens = self.tokenizer.encode(text, add_special_tokens=True)\n",
        "        if len(tokens) <= 2: return torch.tensor(0.0, device=self.device)\n",
        "\n",
        "        total_pll = torch.tensor(0.0, device=self.device, requires_grad=True)\n",
        "        count = 0\n",
        "        \n",
        "        input_ids_list = []\n",
        "        target_ids_list = []\n",
        "        \n",
        "        for i in range(1, len(tokens) - 1):\n",
        "            masked = tokens.copy()\n",
        "            target = masked[i]\n",
        "            masked[i] = self.tokenizer.mask_token_id\n",
        "            input_ids_list.append(masked)\n",
        "            target_ids_list.append(target)\n",
        "            \n",
        "        if not input_ids_list: return torch.tensor(0.0, device=self.device)\n",
        "\n",
        "        input_tensor = torch.tensor(input_ids_list, device=self.device)\n",
        "        target_tensor = torch.tensor(target_ids_list, device=self.device)\n",
        "\n",
        "        outputs = self.model(input_tensor)\n",
        "        logits = outputs.logits\n",
        "        \n",
        "        range_indices = torch.arange(1, len(tokens) - 1, device=self.device)\n",
        "        target_logits = logits[torch.arange(len(input_ids_list)), range_indices]\n",
        "        log_probs = F.log_softmax(target_logits, dim=-1)\n",
        "        \n",
        "        token_plls = log_probs.gather(1, target_tensor.unsqueeze(1)).squeeze()\n",
        "        return token_plls.mean()\n",
        "\n",
        "    def train_epoch(self, pairs):\n",
        "        self.model.train()\n",
        "        epoch_losses = []\n",
        "        \n",
        "        for pair in tqdm(pairs, desc=\"Training\", leave=False):\n",
        "            self.optimizer.zero_grad()\n",
        "            \n",
        "            pll_stereo = self.pll_score_with_grad(pair['stereotype'])\n",
        "            pll_anti = self.pll_score_with_grad(pair['anti_stereotype'])\n",
        "            \n",
        "            # --- NEW LOSS FUNCTION ---\n",
        "            # 1. Bias component: minimize difference\n",
        "            bias_loss = (pll_stereo - pll_anti) ** 2\n",
        "            \n",
        "            # 2. Utility component: maximize probability (minimize negative log prob)\n",
        "            # We subtract the sum because PLL is log-prob (negative).\n",
        "            # Maximizing PLL = Minimizing -PLL.\n",
        "            utility_loss = -1 * (pll_stereo + pll_anti)\n",
        "            \n",
        "            # Combined Loss\n",
        "            loss = bias_loss + (self.alpha * utility_loss)\n",
        "            # -------------------------\n",
        "            \n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            epoch_losses.append(loss.item())\n",
        "            \n",
        "        return np.mean(epoch_losses)\n",
        "```\n",
        "\n",
        "### Re-Running the Experiment\n",
        "\n",
        "1.  **Update the Trainer Class:** Paste the code above into your notebook.\n",
        "2.  **Lower Learning Rates:** The aggressive LRs (`1e-2` for Prompt) likely contributed to the collapse.\n",
        "      * **LoRA:** Use `1e-4` (standard).\n",
        "      * **Prompt Tuning:** Use `1e-3` (conservative).\n",
        "3.  **Re-Run Round 2 (LoRA) Only:** Start with LoRA. If the perplexity stays low (e.g., \\< 50), then run Prompt Tuning.\n",
        "\n",
        "**Would you like me to provide the specific cell to re-run just the LoRA training with these safer settings?**"
      ],
      "metadata": {
        "id": "27e3a04f-a65a-4c4c-b451-4425a2956ea9"
      }
    }
  ]
}